# 数据挖掘 chapter1

- 大数据的4V特性
  - Volume大量化
  - variety多样化
  - velocity快速化
  - value价值密度低

- 大数据时代的产生
  - 硬件成本的降低
  - 网络带宽的提升
  - 云计算的兴起
  - 网络技术的发展
  - 智能终端的普及
  - 物联网

- 数据挖掘定义
  - 从大量数据中挖掘那些令人感兴趣的,有用的,隐含的,先前未知的和可能有用的模式或者知识

- 数据挖掘的主要任务
  - 关联分析
  - 分类与预测
  - 聚类分析
  - 孤立点分析

# 数据挖掘 Chapter3

- 多维数据与OLAP操作
  - 上卷 ROLLUP
    - 在某一个维度的概念分层上向上攀升,其实就是维度的提升,比如芝加哥和纽约被提升成了美国
  - 下钻 DRILL_DOWN
    - 由不太详细的数据获得更加详细的数据,就是数据的拆分,比如原来的季度拆成每个月
  - 切片和切块 slice and dice
    - 投影与选择操作,其实就是根据条件选择,切片就是选择列,切块就是选择元素
  - 转轴 PIVOT
    - 立方体的重定位，可视化，或将一个3维立方体转化维一个2维平面序列,其实就是数据变化,横纵轴的变化

# 数据挖掘 Chapter4

- 关联规则
  - 频繁项集
    - 项集
      - 包含多个元素的集合
    - 支持度计数
      - 包含某个特定项集的事务个数(其实就是记录的个数)
    - 支持度
      - 支持度计数与总的事务数的比值
    - 频繁项集
      - 大于最小支持度阈值的项集
    - 关联规则
      - 形似X->Y的蕴含表达式,X,Y是不相交的项集
    - 置信度
      - 确定Y在包含X的事务中出现的频繁程度,用X并Y的支持度除以X的支持度
  - 如何挖掘关联规则
    
    1. 频繁项集的产生,根据最小支持度阈值
    2. 强规则的产生,根据最小置信度阈值
  - 挖掘方法
    - Brute-force方法(蛮力方法)
      - 格结构:把所有组合都列出来作为候选项集,认为都有可能,计算所有候选项集的支持度
      - 时间复杂度高,开销很大
    - Apriori算法 
      - 使用了频繁项集性质的先验（Prior）知识。
        - 如果一个项集是频繁的，则它的所有子集一定也是频繁的；
        - 相反，如果一个项集是非频繁的，则它的所有超集也一定是非频繁的；
      - 提升Apriori算法
        - 散列项集计数
          - 利用散列的技术
        - 事务压缩
          - 不包含频繁K项集的事物也不会包含频繁K+1项集,可以加标记或者删除
        - 划分
          - 就是分而治之的思想,先求子集的频繁模式,再求全局的频繁模式
        - 采样
          - 多次抽样
    - FP增长算法
      - FP树不同于Apriori算法的模式,他是先建树,然后在统计
      - 如何建树
        - 首先对支持度排序,去掉非频繁项
        - 然后扫描事务,根据路径重叠形成FP树,共享路径
      - 特点:
        - FP树比未压缩的数据要小
        - FP树的大小依赖于排序的顺序
        - FP树中有一个指针链表,便于快速访问
      - 如何进行频繁模式挖掘
        - 首先,扫描第一遍得到项头表, 排序并且取出非频繁
        - 然后,扫描第二遍去除事务中的非频繁,并排序
        - 开始建立FP树,共享路径
        - 寻找条件模式基,获得频繁模式 

# 数据挖掘 Chapter5
- KNN分类算法

  - 步骤:
    - 算距离
    - 找邻居
    - 做分类
  - 缺点:
    - 计算量大
    - K值难以估计
    - 对不平衡数据不友好
  - 改进方法:
    - KD树划分空间,减少计算量

- 决策树

  - 决策属性
    - ID3
      - 信息增益
    - c4.5
      - 信息增益率
    - cart
      - gini不纯度
  - 过拟合与剪枝
    - 预剪枝:提前设定阈值,停止划分
    - 后剪枝:生成全树以后,进行剪枝

- SVM

  - 间隔

    - 最大间隔化

    - 软间隔

  - 对偶

    - 同过间隔最大化转换为最优化问题,通过KKT条件转换为对偶问题

  - 核技巧

    - 解决线性不可分问题

- 神经网络

- 分类器评价指标

  - 精度
  - 召回率



## 数据挖掘Chapter6

- 聚类
  - 划分方法
    - K-means
      - 步骤:
        - 初始化K个值作为簇均值
        - 然后把每个点加入到距离最近的簇(簇均值的距离)中
        - 更新簇均值
        - 计算准则函数,也就是所有簇的所有点到簇均值的距离之和
        - 直到准测函数不发生变化为止
      - 缺点:
        - 必须实现给出K
        - 对初值敏感
        - 不适合非球状的簇
        - 对噪声敏感
    - K-Medoids
      - 步骤:
        - 初始化K个点作为簇的中心点
        - 然后把其他点全部根据到中心点距离分给每个簇
        - 尝试簇内所有点作为中心点,然后计算代价(之前的距离减之后距离的和)
        - 如果所有的代价都大于0,那么就结束
        - 如果有小于0的,就用代价最小的那个非中心点替换中心点,形成新的簇
        - 重复直到没有新的簇生成
      - 缺点:
        - 计算量大
  - 层次的方法
    - 层次凝聚
      - Agnes
        - 最开始把所有的个体作为一个单独的类
        - 然后根据不断合并距离最近的两个簇
        - 两个簇的距离通过两个簇中相离最近的点的距离表示
    - 层次分裂
      - Diana
    - 把距离作为合并或者分裂的标准这种方法不需要输入聚类的数目K,但需要一个终止条件
    - 可以设置不同的距离度量
  - 基于密度的方法
  - 基于网格的方法



